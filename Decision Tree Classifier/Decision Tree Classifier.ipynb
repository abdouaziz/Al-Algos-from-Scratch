{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "Decision Trees are ML algorithms that progressively divide data sets into smaller data groups based on a descriptive feature, until they reach sets that are small enough to be described by some label.\n",
    "\n",
    "### Main DT Algorithms\n",
    "####  1. CHAID - Chi-squared Automatic Interaction Detection\n",
    "When building **classification trees**, CHAID relies on chi-squared tests to find the best split at each step. In other words, it chooses the independent variable that has the strongest interaction with the dependent variable. For **regression trees**, CHAID relies on F-tests to calculate the difference between two population means.\n",
    "\n",
    "#### 2. CART - Classification And Regression Trees\n",
    "In the case of **Classification Trees**, CART algorithm uses a metric called **Gini Impurity** to create decision points for classification tasks. Gini Impurity gives an idea of how fine a split is. In the case of **Regression Trees**, CART algorithm looks for splits that minimize the **Least Square Deviation (LSD)**, choosing the partitions that minimize the result over all possible options. The LSD (sometimes referred as “variance reduction”) metric minimizes the sum of the squared distances (or deviations) between the observed values and the predicted values.\n",
    "\n",
    "#### 3. ID3 - Iterative Dichotomiser 3\n",
    "It is mostly used for classification tasks. ID3 splits data attributes (dichotomizes) to find the most dominant features, performing this process iteratively to select the DT nodes in a top-down approach. For the splitting process, ID3 uses the **Information Gain** metric to select the most useful attributes for classification. Information Gain is directly linked to the concept of **Entropy**, which is the measure of the amount of uncertainty or randomness in the data.\n",
    "\n",
    "#### 4. C 4.5 \n",
    "It is successor of ID3. C4.5 can handle both continuous and categorical data, making it suitable to generate Regression and Classification Trees. Additionally, it can deal with missing values by ignoring instances that include non-existing data. Unlike ID3, C4.5 uses **Gain Ratio** for its splitting process. Gain Ratio is a modification of the Information Gain concept that reduces the bias on DTs. Another capability of C4.5 is that it can prune DTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will implement CART algorithm for classification task\n",
    "#### Important points\n",
    "1. The representation of the CART model is a binary tree.\n",
    "2. For regression, The cost function that is minimized to choose split points is the sum squared error across all training samples that fall within the node.\n",
    "3. For classification, The Gini cost function is used which provides an indication of how pure the nodes are, where node purity refers to how mixed the training data assigned to each node is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gini Index\n",
    "* Name of the cost function used to evaluate splits in the dataset.\n",
    "* Performs only binary splits\n",
    "* Higher the value of Gini higher the homogeneity. A perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group result in a Gini score of 0.5\n",
    "\n",
    "**Steps to calculate Gini**:\n",
    "1. Calculate Gini for sub-nodes, using formula sum of square of probability.\n",
    "2. Calculate Gini for split using weighted Gini score of each node of that split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Gini\\;for\\;node = 1 - \\sum_{all\\;classes} p^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ where \\; p = probability\\;of\\;each\\;class $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Gini\\;for\\;split = \\sum_{both\\;nodes} Gini\\;for\\;node * \\frac{node\\;size}{total\\;size} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Terminal Node\n",
    "When to decide to stop growing the tree\n",
    "\n",
    "**Maximum Tree Depth** : This is the maximum number of nodes from the root node of the tree. Once a maximum depth of the tree is met, we must stop splitting adding new nodes. Deeper trees are more complex and are more likely to overfit the training data.\n",
    "\n",
    "**Minimum Node Records** :  This is the minimum number of training patterns that a given node is responsible for. Once at or below this minimum, we must stop splitting and adding new nodes. Nodes that account for too few training patterns are expected to be too specific and are likely to overfit the training data.\n",
    "\n",
    "There is one more condition. It is possible to choose a split in which all rows belong to one group. In this case, we will be unable to continue splitting and adding child nodes as we will have no records to split on one side or another.\n",
    "\n",
    "Now we have some ideas of when to stop growing the tree. When we do stop growing at a given point, that node is called a terminal node and is used to make a final prediction.\n",
    "\n",
    "This is done by taking the group of rows assigned to that node and selecting the most common class value in the group. This will be used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        self.max_depth = 0\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.n_classes = None\n",
    "    \n",
    "    def gini_index(self,groups, y):\n",
    "        n_instances = len(groups[0])+len(groups[1])  # count of all samples\n",
    "        gini = 0.0 # sum weighted Gini index for each group\n",
    "        for indexes in groups:\n",
    "            size = len(indexes)\n",
    "            if size == 0: continue # avoid divide by zero\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in np.unique(y):\n",
    "                p = (y[indexes]==class_val).sum()/size \n",
    "                score += p*p\n",
    "            # weight the group score by its relative size\n",
    "            gini +=  (1-score) * (size / n_instances)\n",
    "        return gini\n",
    "    \n",
    "    def get_split(self,X,y):\n",
    "        b_index, b_value, b_score, b_groups = float('inf'), float('inf'), float('inf'), None\n",
    "        for col_ind in range(X.shape[1]): #for each features\n",
    "            for val in np.unique(X[:,col_ind]): #for each unique value of that feature\n",
    "\n",
    "                #left_index indexes lower than val for feature, right_index indexes greater that val for feature\n",
    "                left_index = np.reshape( np.argwhere(X[:,col_ind]<val) ,(-1,))\n",
    "                right_index = np.reshape( np.argwhere(X[:,col_ind]>=val) ,(-1,))\n",
    "                \n",
    "                #find gini index\n",
    "                gini = self.gini_index((left_index,right_index), y)\n",
    "                \n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = col_ind, val, gini, (left_index, right_index)\n",
    "\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "    \n",
    "    \n",
    "    def to_terminal(self,classes):\n",
    "        # Create a terminal node value\n",
    "        cls,cnt = np.unique(classes,return_counts=True)\n",
    "        probs = np.zeros(self.n_classes)\n",
    "        for cl,cn in zip(cls,cnt): probs[cl] = cn/sum(cnt)\n",
    "        return cls[np.argmax(cnt)], probs\n",
    "    \n",
    "    def split(self, node, X, y, max_depth, min_samples_split, depth):\n",
    "        self.max_depth = max(depth,self.max_depth)\n",
    "        left, right = node.pop('groups')\n",
    "        \n",
    "        # check for a no split\n",
    "        if len(left)==0 or len(right)==0:\n",
    "            node['left'] = node['right'] = self.to_terminal(y[np.append(left,right)])\n",
    "            return\n",
    "        \n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(y[left]), self.to_terminal(y[right])\n",
    "            return\n",
    "        \n",
    "        # process left child\n",
    "        if len(left) <= min_samples_split:\n",
    "            node['left'] = self.to_terminal(y[left])\n",
    "        else:\n",
    "            node['left'] = self.get_split(X[left],y[left])\n",
    "            self.split(node['left'], X[left], y[left], max_depth, min_samples_split, depth+1)\n",
    "        \n",
    "        # process right child\n",
    "        if len(right) <= min_samples_split:\n",
    "            node['right'] = self.to_terminal(y[right])\n",
    "        else:\n",
    "            node['right'] = self.get_split(X[right],y[right])\n",
    "            self.split(node['right'],X[right],y[right], max_depth, min_samples_split, depth+1)\n",
    "                \n",
    "    def fit(self,X,y, max_depth=None, min_samples_split=2):\n",
    "        self.X, self.y, max_depth = X, y, float('inf') if max_depth==None else max_depth\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.root = self.get_split(X,y)\n",
    "        self.split(self.root, X, y, max_depth, min_samples_split,1)\n",
    "        \n",
    "    def predict(self,rows):\n",
    "        return np.array([ self.predict_row(row,self.root)[0] for row in rows ])\n",
    "        \n",
    "    def predict_proba(self,rows):\n",
    "        return np.array([ self.predict_row(row,self.root)[1] for row in rows ])\n",
    "    \n",
    "    def predict_row(self,row,node):\n",
    "        if row[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):  return self.predict_row(row,node['left'])\n",
    "            else: return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict): return self.predict_row(row,node['right'])\n",
    "            else: return node['right']\n",
    "            \n",
    "    def score(self,X,y): \n",
    "        return (y==self.predict(X)).sum()/len(y)\n",
    "    \n",
    "    @property \n",
    "    def depth(self): return self.max_depth\n",
    "    \n",
    "    @property \n",
    "    def tree_(self): return self.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study : Banknote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of Wavelet Transformed Image</th>\n",
       "      <th>Skewnes of Wavelet Transformed Image</th>\n",
       "      <th>Curtosis of Wavelet Transformed Image</th>\n",
       "      <th>Entropy of Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1.25720</td>\n",
       "      <td>4.873100</td>\n",
       "      <td>-5.28610</td>\n",
       "      <td>-5.87410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3.37560</td>\n",
       "      <td>-4.095100</td>\n",
       "      <td>4.36700</td>\n",
       "      <td>1.06980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3.27180</td>\n",
       "      <td>1.783700</td>\n",
       "      <td>2.11610</td>\n",
       "      <td>0.61334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.77124</td>\n",
       "      <td>9.086200</td>\n",
       "      <td>-1.22810</td>\n",
       "      <td>-1.49960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>-1.70150</td>\n",
       "      <td>-0.010356</td>\n",
       "      <td>-0.99337</td>\n",
       "      <td>-0.53104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variance of Wavelet Transformed Image  \\\n",
       "1346                                1.25720   \n",
       "496                                 3.37560   \n",
       "94                                  3.27180   \n",
       "452                                 0.77124   \n",
       "809                                -1.70150   \n",
       "\n",
       "      Skewnes of Wavelet Transformed Image  \\\n",
       "1346                              4.873100   \n",
       "496                              -4.095100   \n",
       "94                                1.783700   \n",
       "452                               9.086200   \n",
       "809                              -0.010356   \n",
       "\n",
       "      Curtosis of Wavelet Transformed Image  Entropy of Image  Class  \n",
       "1346                               -5.28610          -5.87410      1  \n",
       "496                                 4.36700           1.06980      0  \n",
       "94                                  2.11610           0.61334      0  \n",
       "452                                -1.22810          -1.49960      0  \n",
       "809                                -0.99337          -0.53104      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_banknote.txt',header=None,\n",
    "                   names=[ 'Variance of Wavelet Transformed Image', 'Skewnes of Wavelet Transformed Image',\n",
    "                            'Curtosis of Wavelet Transformed Image','Entropy of Image','Class'])\n",
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((946, 4), (426, 4), (946,), (426,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split(X,y,test_size=0.3):\n",
    "    indexes = np.random.choice( [False,True], len(y), p=[test_size,1-test_size], replace=True )\n",
    "    return X[indexes],X[~indexes],y[indexes],y[~indexes]\n",
    "\n",
    "X = data.drop('Class',axis=1).values\n",
    "y = data.Class.values\n",
    "\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X,y)\n",
    "X_train.shape,X_val.shape,Y_train.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,Y_train,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9225352112676056, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_val,Y_val),dt.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study : Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length</th>\n",
       "      <th>Sepal width</th>\n",
       "      <th>Petal length</th>\n",
       "      <th>Petal Width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal length  Sepal width  Petal length  Petal Width  Class\n",
       "71            6.1          2.8           4.0          1.3      1\n",
       "19            5.1          3.8           1.5          0.3      0\n",
       "77            6.7          3.0           5.0          1.7      1\n",
       "131           7.9          3.8           6.4          2.0      2\n",
       "61            5.9          3.0           4.2          1.5      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data',header=None,names=['Sepal length','Sepal width', 'Petal length', 'Petal Width', 'Class'])\n",
    "data.Class.replace({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2},inplace=True)\n",
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93, 4), (57, 4), (93,), (57,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split(X,y,test_size=0.3):\n",
    "    indexes = np.random.choice( [False,True], len(y), p=[test_size,1-test_size], replace=True )\n",
    "    return X[indexes],X[~indexes],y[indexes],y[~indexes]\n",
    "\n",
    "X = data.drop('Class',axis=1).values\n",
    "y = data.Class.values\n",
    "\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X,y)\n",
    "X_train.shape,X_val.shape,Y_train.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([17, 16, 24]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_val,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,Y_train,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8245614035087719, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_val,Y_val),dt.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
