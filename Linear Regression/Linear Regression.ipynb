{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Derivation\n",
    "\n",
    "Let best fit line be : $ \\hat Y_i = b X_i + a $ and the sum of squared error(S) is $ S = \\sum ( Y_i - \\hat Y_i )^2 $ which is to be minimized.\n",
    "\n",
    "S is to be minimized at the value of a and b, So $ \\partial S / \\partial a = 0 $ and $ \\partial S / \\partial b $\n",
    "\n",
    "So, First Condition\n",
    "\n",
    "$$ \\frac{\\partial S}{ \\partial a} = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial a}( \\sum_{i=0}^n ( Y_i - \\hat Y_i )^2 ) = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial a} \\sum_{i=0}^n ( Y_i - b X_i - a )^2 ) = 0 $$\n",
    "\n",
    "$$ \\sum_{i=0}^n -2( Y_i - b X_i - a ) = 0 $$\n",
    "\n",
    "$$ 2 ( na - \\sum_{i=0}^n Y_i + b \\sum_{i=0}^n X_i ) = 0 $$\n",
    "\n",
    "$$ a = \\frac{ \\sum_{i=0}^n Y_i - b \\sum_{i=0}^n X_i }{n} $$\n",
    "\n",
    "$$ a = \\bar Y - b \\bar X $$\n",
    "\n",
    "This means constant a (the y-intercept) is set such that the line must go through the mean of x and y. Make sense because this point is the \"center\" of the data cloud\n",
    "\n",
    "Now, second Condition\n",
    "\n",
    "$$ \\frac{\\partial S}{ \\partial a} = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial b}( \\sum_{i=0}^n ( Y_i - \\hat Y_i )^2 ) = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial b} (\\sum_{i=0}^n ( Y_i - b X_i - a )^2 ) = 0 $$\n",
    "\n",
    "$$  \\sum_{i=0}^n -2X_i( Y_i - b X_i - a ) = \\sum_{i=0}^n -2( X_iY_i - b X_i^2 - aX_i ) = 0 $$\n",
    "\n",
    "substituting value of a,\n",
    "\n",
    "$$  \\sum_{i=0}^n ( X_iY_i - b X_i^2 -  X_i \\bar Y + b  X_i \\bar X ) = 0 $$\n",
    "\n",
    "$$   \\sum_{i=0}^n (X_iY_i -  X_i \\bar Y) - b \\sum_{i=0}^n ( X_i^2 - X_i \\bar X) = 0 $$\n",
    "\n",
    "$$   b = \\frac{\\sum_{i=0}^n (X_iY_i -  X_i \\bar Y)}{\\sum_{i=0}^n ( X_i^2 - X_i \\bar X)} $$\n",
    "\n",
    "We can also note that,\n",
    "\n",
    "$$ \\sum_{i=0}^n ( \\bar X ^2 - X_i \\bar X ) = 0, \\; and \\sum_{i=0}^n( \\bar X \\bar Y - Y_i \\bar X ) = 0 $$\n",
    "\n",
    "Using this, b can also be written as\n",
    "\n",
    "$$ b = \\frac{\\sum_{i=0}^n ( X_iY_i -  X_i \\bar Y) + \\sum_{i=0}^n( \\bar X \\bar Y - Y_i \\bar X ) }{\\sum_{i=0}^n ( X_i^2 - X_i \\bar X) + \\sum_{i=0}^n ( \\bar X ^2 - X_i \\bar X ) }  $$\n",
    "\n",
    "$$ b = \\frac{ \\sum_{i=0}^n \\bigg( X_i (Y_i -\\bar Y) - \\bar X ( Y_i - \\bar Y ) \\bigg) }{ \\sum_{i=0}^n \\bigg( X_i^2 - 2 X_i \\bar X +  \\bar X ^2 \\bigg) }   $$\n",
    "\n",
    "$$ b = \\frac{ \\frac{1}{n} \\sum_{i=0}^n ( X_i - \\bar X )(Y_i - \\bar Y)  }{ \\frac{1}{n} \\sum_{i=0}^n (X_i - \\bar X)^2 }  $$\n",
    "\n",
    "$$ b = \\frac{covariance( X_i,Y_i )}{variance(X_i)}  $$\n",
    "\n",
    "$$ b = \\frac{ r \\sigma_x \\sigma_y }{ \\sigma_x^2 }, where \\; r = pearson's \\; r $$\n",
    "\n",
    "$$ b = \\frac{ r*\\sigma_y }{\\sigma_x} $$\n",
    "\n",
    "\n",
    "#### For multiple independent variables\n",
    "\n",
    "$$ a = \\bar Y - \\sum b \\bar X $$\n",
    "\n",
    "$$ b = (X^TX)^{-1} X^T Y $$\n",
    "\n",
    "> Calculating $ (X^TX)^{-1} $ is O(n^3). So if we have a very large number of features, the normal equation will be slow. In practice, when n exceeds 10,000 it might be a good time to go from a normal solution to an iterative process.\n",
    "\n",
    "> Non invertibility of $X^TX$.\n",
    "\n",
    "> 1. Redundant Features. If two features are linearly dependent.\n",
    "\n",
    "> 2. Too many features. E.g. m<n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Math  Reading  Writing\n",
       "0    48       68       63\n",
       "1    62       81       72\n",
       "2    79       80       78\n",
       "3    76       83       79\n",
       "4    59       64       62"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('student.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.values[:,[0,1]]\n",
    "y = data.values[:,-1]\n",
    "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.44746983, 13.33854736]), 68.616)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b =  np.dot( np.linalg.inv(np.dot(X.T, X)), np.dot( X.T, y ))\n",
    "a = y.mean() - np.sum(b * X.mean(axis=0))\n",
    "b,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.dot(X,b)+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9098901726717316"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rsquare(y_true,y_pred):\n",
    "    return 1-( np.sum((y_true - y_pred)**2)/ np.sum( (y_true-y_true.mean())**2 ) )\n",
    "rsquare( y, y_pred )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
