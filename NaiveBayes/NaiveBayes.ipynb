{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are a collection of classification algorithms based on **Bayesâ€™ Theorem**. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n",
    "\n",
    "**Gaussian Naive Bayes**: continuous values associated with each feature are assumed to be distributed according to a Gaussian distribution. A Gaussian distribution is also called Normal distribution. When plotted, it gives a bell shaped curve which is symmetric about the mean of the feature values.\n",
    "\n",
    "**Multinomial Naive Bayes**: Feature vectors represent the frequencies with which certain events have been generated by a multinomial distribution. This is the event model typically used for document classification. Its is used when we have discrete data (e.g. movie ratings ranging 1 and 5 as each rating will have certain frequency to represent). In text learning we have the count of each word to predict the class or label.\n",
    "\n",
    "**Bernoulli Naive Bayes**: In the multivariate Bernoulli event model, features are independent booleans (binary variables) describing inputs. Like the multinomial model, this model is popular for document classification tasks, where binary term occurrence(i.e. a word occurs in a document or not) features are used rather than term frequencies(i.e. frequency of a word in the document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial and Bernoulli Naive Bayes\n",
    "Lets look at following example\n",
    "\n",
    "| X1 | X2 | X3 | y |\n",
    "|--------|--------|--------|-------|\n",
    "| A      | N      | E      | 0     |\n",
    "| A      | M      | E      | 0     |\n",
    "| B      | M      | G      | 0     |\n",
    "| B      | L      | F      | 0     |\n",
    "| A      | K      | G      | 1     |\n",
    "| B      | L      | E      | 1     |\n",
    "| A      | M      | G      | 1     |\n",
    "| B      | N      | F      | 1     |\n",
    "| B      | L      | G      | 1     |\n",
    "\n",
    "\n",
    "$$ P(\\frac{y}{X}) = \\frac{ P(X|y) P(y) }{P(X)} $$\n",
    "\n",
    "$ P(X) = P(X1) P(X2) P(X3) $, since all the features are independent of each other\n",
    "\n",
    "$$ P( \\frac{y}{x_1,x_2,...,x_n}) = \\frac{ P(y) \\prod_{i=1}^n P(x_i/y) }{ \\prod_{i=1}^n P(x_i) } $$\n",
    "\n",
    "Since, $ \\prod_{i=1}^n P(x_i) $ is common y=(0,1) so we can ignore that\n",
    "\n",
    "$$ y = argmax_y P(y) \\prod_{i=1}^n P(x_i/y)  $$\n",
    "\n",
    "Total samples = 9\n",
    "\n",
    "$ P(y=0) = \\frac{4}{9}, P(y=1) = \\frac{5}{9} $\n",
    "\n",
    "$ P(\\frac{X1=A}{y=0} ) = \\frac{2}{4}, P(\\frac{X1=B}{y=0}) = \\frac{2}{4}, P(\\frac{X1=A}{y=1} ) = \\frac{2}{5}, P(\\frac{X1=B}{y=1} ) = \\frac{3}{5} $\n",
    "\n",
    "$ P(\\frac{X2=K}{y=0}) = \\frac{0}{4}, P(\\frac{X2=L}{y=0}) = \\frac{1}{4}, P(\\frac{X2=M}{y=0}) = \\frac{2}{4}, P(\\frac{X2=N}{y=0}) = \\frac{1}{4}, P(\\frac{X2=K}{y=1}) = \\frac{1}{5}, P(\\frac{X2=L}{y=1}) = \\frac{2}{5}, P(\\frac{X2=M}{y=1}) = \\frac{1}{5}, P(\\frac{X2=N}{y=1}) = \\frac{1}{5} $\n",
    "\n",
    "$ P(\\frac{X3=E}{y=0} ) = \\frac{2}{4}, P(\\frac{X3=F}{y=0} ) = \\frac{1}{4}, P(\\frac{X3=G}{y=0} ) = \\frac{1}{4}, P(\\frac{X3=E}{y=1} ) = \\frac{1}{5}, P(\\frac{X3=F}{y=1} ) = \\frac{1}{5}, P(\\frac{X3=G}{y=1} ) = \\frac{3}{5}, $\n",
    "\n",
    "Lets find out probs for a sample\n",
    "\n",
    "$ P(\\frac{y=0}{ X1=B, X2=M, X3=E }) = P(y=0) * P(\\frac{X1=B}{y=0})) * P(\\frac{X2=M}{y=0}) * P(\\frac{X3=E}{y=0}) = \\frac{4}{9}*\\frac{2}{4}*\\frac{2}{4}*\\frac{2}{4} = 0.05555 $\n",
    "\n",
    "$ P(\\frac{y=1}{ X1=B, X2=M, X3=E }) = P(y=1) * P(\\frac{X1=B}{y=1})) * P(\\frac{X2=M}{y=1}) * P(\\frac{X3=E}{y=1}) = \\frac{5}{9}*\\frac{3}{5}*\\frac{1}{5}*\\frac{1}{5} = 0.01333 $\n",
    "\n",
    "$ P(y=0) = \\frac{0.05555}{0.05555+0.01333} = 0.8064, P(y=1) = \\frac{0.01333}{0.05555+0.01333} =  0.1935  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = np.array( [ ['A','N','E'], ['A','M','E'], ['B','M','G'], ['B','L','F'], \n",
    "                ['A','K','G'], ['B','L','E'], ['A','M','G'], ['B','N','F'], ['B','L','G']])\n",
    "y = np.array( [0,0,0,0,1,1,1,1,1] )\n",
    "\n",
    "X = np.zeros_like(X_temp, dtype=np.int)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X[:,0] = LabelEncoder().fit_transform(X_temp[:,0])\n",
    "X[:,1] = LabelEncoder().fit_transform(X_temp[:,1])\n",
    "X[:,2] = LabelEncoder().fit_transform(X_temp[:,2])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80645161, 0.19354839])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "summary = []\n",
    "for label in sorted(np.unique(y)):\n",
    "    X_label = X[y==label]\n",
    "    array = []\n",
    "    for feat_ind in range(X_label.shape[1]):\n",
    "        probs = defaultdict(float)\n",
    "        feats,cnts = np.unique(X_label[:,feat_ind], return_counts=True)\n",
    "        for feat,cnt in zip(feats,cnts):\n",
    "            probs[feat] = cnt/(y==label).sum()\n",
    "        array.append(probs)\n",
    "    summary.append(array)\n",
    "\n",
    "def predict_row(x):\n",
    "    probs = []\n",
    "    labels, cnts = np.unique( y, return_counts=True )\n",
    "    for label, cnt in zip(labels,cnts):\n",
    "        prob = cnt/sum(cnts)\n",
    "        for feat_ind in range(len(x)):\n",
    "            prob *= summary[int(label)][feat_ind][x[feat_ind]]\n",
    "        probs.append(prob)\n",
    "    return np.array(probs)/sum(probs)\n",
    "predict_row( [1,2,0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guassian Naive Bayes\n",
    "\n",
    "$$  P(x_i|y) = \\frac{1}{\\sqrt{2\\pi\\sigma_y^2}}exp\\bigg( -\\frac{ (x_i-\\mu_y)^2 }{ 2\\sigma_y^2 } \\bigg)  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "for label in sorted(np.unique(y)):\n",
    "    X_label = X[ y==label ]\n",
    "    means, std, cnt = X_label.mean(axis=0), X_label.std(axis=0)*np.sqrt( len(X_label)/(len(X_label)-1) ), len(X_label)\n",
    "    summary.append( (means, std, cnt) )\n",
    "\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = np.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent\n",
    "\n",
    "def predict_proba( x ):\n",
    "    probs = []\n",
    "    for means,stds,cnt in summary:\n",
    "        prob = cnt/len(y)\n",
    "        for feature_index in range(len(x)):\n",
    "            prob = prob*calculate_probability( x[feature_index], means[feature_index], stds[feature_index] )\n",
    "        probs.append(prob)\n",
    "    return np.array(probs)/sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411078717201166"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_banknote.txt',header=None).values\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "y_pred =  np.argmax(np.array([predict_proba(x) for x in X]), axis=1)\n",
    "(y_pred == y).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
